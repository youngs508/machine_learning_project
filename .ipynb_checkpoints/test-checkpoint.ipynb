{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47d6328e-488d-4753-894c-72e59cf5e8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dc24ee2-231d-4796-8fec-8e4d0b44fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7437b6a3-0956-4caf-a8a6-1334dc4f30a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor: \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.y_btcHigh_pred = []\n",
    "        self.x_btcHigh_train = []\n",
    "        self.y_btcHigh_train = []\n",
    "        \n",
    "    def getAllPredictionsBTCHigh(self):\n",
    "        return self.y_btcHigh_pred\n",
    "    \n",
    "    def getAllXTrainBTCHigh(self):\n",
    "        return self.x_btcHigh_train\n",
    "    \n",
    "    def getAllYTrainBTCHigh(self):\n",
    "        return self.y_btcHigh_train\n",
    "    \n",
    "        \n",
    "    def _predictWithLinearRegression(self, date=None):\n",
    "    \n",
    "        model = LinearRegressionRegularization()\n",
    "        utils = Utils()\n",
    "        \n",
    "        #New training data\n",
    "        if (date!=None): \n",
    "            self.X = utils._newTrainingData({'Date': date}, self.X)\n",
    "            \n",
    "        # Split the data into training subsets\n",
    "        train_data, test_data, = model._split(self.X, self.y, ratio=0.7, random_state=123 )\n",
    "        X_train_btcHigh = train_data.drop(columns=['btcHigh'])\n",
    "        y_train_btcHigh = train_data['btcHigh']\n",
    "        #Adjust training data \n",
    "        X_train_btcHigh = utils._updateTrainingData(X_train_btcHigh)\n",
    "        X_train_btcHigh = utils._replaceNanX(X_train_btcHigh)\n",
    "        has_nan = X_train_btcHigh.isna().any().any()\n",
    "        if (has_nan != True):\n",
    "            #Predict\n",
    "            y_pred_btcHigh = model._predict(X_train_btcHigh, y_train_btcHigh)\n",
    "        else:\n",
    "            print (\"Training Data contains Nan values, \", has_nan)\n",
    "        pd.options.mode.chained_assignment = None  #Hide warning\n",
    "        X_train_btcHigh[\"Date\"] = utils._updateDate(X_train_btcHigh)\n",
    "        \n",
    "        self.y_btcHigh_pred = y_pred_btcHigh \n",
    "        self.x_btcHigh_train = X_train_btcHigh \n",
    "        self.y_btcHigh_train = y_train_btcHigh \n",
    "        \n",
    "        return y_pred_btcHigh.tail(1).to_string(index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa67ac84-bbd5-4b19-8c84-84150e16e293",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionRegularization:\n",
    "    def __init__(self, max_iter=2,  learningRate=80, random_state=None):\n",
    "        self.max_iter_ = max_iter\n",
    "        self.alpha = learningRate\n",
    "        self.random_state_ = random_state\n",
    "        self.w_ = np.random.randint(0, 1, 17)\n",
    "        self.w0 = 0\n",
    "        \n",
    "    def _split(self, X, y, ratio, random_state):\n",
    "        header = X.columns\n",
    "        # remove header for shuffling \n",
    "        x_data = X.values\n",
    "\n",
    "        random.seed(random_state)\n",
    "        train_ratio = ratio\n",
    "        test_ratio = 1 - train_ratio\n",
    "        \n",
    "        total_data_sample = len(X)\n",
    "        train_samples = int(total_data_sample * train_ratio)\n",
    "        test_samples = total_data_sample - train_samples\n",
    "\n",
    "        random.shuffle(x_data)\n",
    "        shuffled_data = pd.DataFrame(x_data, columns=header)\n",
    "\n",
    "        train_data = shuffled_data.head(train_samples)\n",
    "        test_data = shuffled_data.head(test_samples)\n",
    "        \n",
    "        return train_data, test_data\n",
    "        \n",
    "    def _predict(self, x_train, y_train):\n",
    "        #TO-DO : Add Regularization \n",
    "        \n",
    "        x_train_array = x_train.to_numpy()\n",
    "        m = len(y_train) # number of features \n",
    "        #Initial weights \n",
    "        tempWeights = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0] \n",
    "        tempW0 = 0\n",
    "        y_pred_btc = tempW0\n",
    "        \n",
    "        for idx in range (self.max_iter_): \n",
    "            for i in range (m):\n",
    "                summation = []\n",
    "                xi = x_train_array[i, :]\n",
    "                y_pred_btc = tempW0\n",
    "                for k in range (17):\n",
    "                    y_pred_btc += self.w_[k] * xi[k]\n",
    "                summation.append(y_pred_btc - y_train)\n",
    "\n",
    "                derivative = 2/m * sum(summation)\n",
    "                tempW0 = self.w0 - (self.alpha * derivative)\n",
    "\n",
    "            for j in range (17):\n",
    "                for i in range (m): \n",
    "                    summation = []\n",
    "                    xi = x_train_array[i, :]\n",
    "                    y_pred_btc = tempW0 \n",
    "                    for k in range (17):\n",
    "                        y_pred_btc += self.w_[k] * xi[k]  \n",
    "\n",
    "                    summation.append(y_pred_btc - y_train)\n",
    "                derivative = 2/m * sum(summation)\n",
    "                tempWeights.append(self.w_[j] - (self.alpha * derivative))    \n",
    "\n",
    "            #The previous iteration \n",
    "            last_17 = tempWeights[-17:]\n",
    "\n",
    "            #Assigning new weight values to old weights\n",
    "            for n in range (17):\n",
    "                tempWeights[n] = last_17[n]\n",
    "            self.w0 = tempW0\n",
    "            #next iteration\n",
    "\n",
    "        final_weights = tempWeights[:17]\n",
    "        self.w_ = final_weights\n",
    "        \n",
    "        return y_pred_btc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4f73d86-7361-4557-94a3-cb481067426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    \n",
    "    def _updateTrainingData(self, x_train):\n",
    "        for i in x_train.columns:\n",
    "            if i != 'Date':\n",
    "                x_train['yesterday_' +i] = x_train[i]\n",
    "                x_train['twoDaysAgo_' +i] = x_train[i]\n",
    "                x_train['threeDaysAgo_' +i] = x_train[i]\n",
    "                x_train['fourDaysAgo_' +i] = x_train[i]\n",
    "                x_train['fiveDaysAgo_' +i] = x_train[i]\n",
    "                x_train['sixDaysAgo_' +i] = x_train[i]\n",
    "                x_train['sevenDaysAgo_' +i] = x_train[i]\n",
    "                x_train['yesterday_' +i] = x_train['yesterday_' +i].shift(1)\n",
    "                x_train['twoDaysAgo_' +i] = x_train['twoDaysAgo_' +i].shift(2)\n",
    "                x_train['threeDaysAgo_' +i] = x_train['threeDaysAgo_' +i].shift(3)\n",
    "                x_train['fourDaysAgo_' +i] = x_train['fourDaysAgo_' +i].shift(4)\n",
    "                x_train['fiveDaysAgo_' +i] = x_train['fiveDaysAgo_' +i].shift(5)\n",
    "                x_train['sixDaysAgo_' +i] = x_train['sixDaysAgo_' +i].shift(6)\n",
    "                x_train['sevenDaysAgo_' +i] = x_train['sevenDaysAgo_' +i].shift(7)\n",
    "                x_train = x_train.drop(i, axis = 1)\n",
    "        return x_train\n",
    "    \n",
    "    def _updateDate(self, x_train):\n",
    "        x_train[\"Date\"]\n",
    "        x_train['Date'] = x_train['Date'].astype(str)\n",
    "        \n",
    "        for k in range (len(x_train[\"Date\"])):\n",
    "            size = len(x_train[\"Date\"][k])\n",
    "            string = x_train[\"Date\"][k]\n",
    "            substring_to_remove = \".0\"\n",
    "            x_train.loc[k]['Date'] = string.replace(substring_to_remove, \"\")\n",
    "\n",
    "        for k in range (len(x_train[\"Date\"])):\n",
    "            size = len(x_train[\"Date\"][k])\n",
    "            string = x_train[\"Date\"][k]\n",
    "            x_train.loc[k]['Date'] = string[:4] + \"-\" + string[4:]\n",
    "            #print(result)\n",
    "\n",
    "        for k in range (len(x_train[\"Date\"])):\n",
    "            size = len(x_train[\"Date\"][k])\n",
    "            string = x_train[\"Date\"][k]\n",
    "            x_train.loc[k]['Date'] = string[:7] + \"-\" + string[7:]\n",
    "        \n",
    "        return x_train['Date']\n",
    "    \n",
    "    def _replaceNanY(self, y_train):\n",
    "        column_means_7days =  y_train.tail(7).mean()\n",
    "        df_filled = y_train_btcHigh.fillna(column_means_7days)\n",
    "        y_train = df_filled\n",
    "        \n",
    "        return y_train\n",
    "    \n",
    "    def _replaceNanX(self, x_train):\n",
    "        column_means = x_train.mean()\n",
    "        df_filled = x_train.fillna(column_means)\n",
    "        x_train = df_filled\n",
    "        \n",
    "        return x_train\n",
    "    \n",
    "    def _newTrainingData(self, new_row, x_train):\n",
    "        index = len(x_train)\n",
    "        x_train.loc[index] = new_row\n",
    "        x_train_temp = x_train\n",
    "        return x_train_temp\n",
    "\n",
    "    \n",
    "    def _newTrainLabel(self, y_train):\n",
    "        column_means_7days = y_train.tail(7).mean()\n",
    "        new_row = pd.Series({'btcHigh': column_means_7days})\n",
    "        y_train_temp = y_train.append(new_row, ignore_index=True)\n",
    "        return y_train_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d5c0625-16af-4f6a-8434-cc21d6d3ac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4a839e7-7730-4c74-b8ec-762119799805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:62: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  x_train.loc[index] = new_row\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['yesterday_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['twoDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['threeDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['fourDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['fiveDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['sixDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['sevenDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['yesterday_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['twoDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['threeDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['fourDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['fiveDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['sixDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['sevenDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['yesterday_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['twoDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['threeDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['fourDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['fiveDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['sixDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['sevenDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['yesterday_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['twoDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['threeDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['fourDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['fiveDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['sixDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  x_train['sevenDaysAgo_' +i] = x_train[i]\n",
      "C:\\Users\\khain\\AppData\\Local\\Temp\\ipykernel_11424\\4055531942.py:55: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_filled = x_train.fillna(column_means)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 0.127778'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._predictWithLinearRegression('2024-05-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07745ca8-b414-44cd-94bf-774c74987778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
